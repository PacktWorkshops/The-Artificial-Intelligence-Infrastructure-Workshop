{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../../Datasets/clickbait-headlines.tsv \n",
      "Size: 0.55 MBs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataset_filename = \"../../Datasets/clickbait-headlines.tsv\"\n",
    "\n",
    "print(\"File: {} \\nSize: {} MBs\".format(dataset_filename, round(os.path.getsize(dataset_filename)/1024/1024, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Egypt's top envoy in Iraq confirmed killed\", 'Carter: Race relations in Palestine are worse than apartheid', 'After Years Of Dutiful Service, The Shiba Who Ran A Tobacco Shop Retires']\n",
      "['0', '0', '1']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "with open(dataset_filename) as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for line in reader:\n",
    "        try:\n",
    "            data.append(line[0])\n",
    "            labels.append(line[1])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        \n",
    "\n",
    "print(data[:3])\n",
    "print(labels[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of our vectors:\n",
      "(10000, 13169)\n",
      "- - -\n",
      "CPU times: user 816 ms, sys: 146 ms, total: 963 ms\n",
      "Wall time: 906 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(data)\n",
    "print(\"The dimensions of our vectors:\")\n",
    "print(vectors.shape)\n",
    "print(\"- - -\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data type of our vectors\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "- - -\n",
      "The size of our vectors (MB):\n",
      "0.6759414672851562\n",
      "- - -\n",
      "The size of our vectors in dense format (MB):\n",
      "1004.7149658203125\n",
      "- - - \n",
      "Number of non zero elements in our vectors\n",
      "88597\n",
      "- - -\n"
     ]
    }
   ],
   "source": [
    "print(\"The data type of our vectors\")\n",
    "print(type(vectors))\n",
    "print(\"- - -\")\n",
    "print(\"The size of our vectors (MB):\")\n",
    "print(vectors.data.nbytes/1024/1024)\n",
    "print(\"- - -\")\n",
    "print(\"The size of our vectors in dense format (MB):\")\n",
    "print(vectors.todense().nbytes/1024/1024)\n",
    "print(\"- - - \")\n",
    "print(\"Number of non zero elements in our vectors\")\n",
    "print(vectors.nnz)\n",
    "print(\"- - -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 13169)\n",
      "(2000, 13169)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, labels, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.8 ms, sys: 12.8 ms, total: 62.6 ms\n",
      "Wall time: 76.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_classifier = LinearSVC()\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "predictions = svm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction, label\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 1\n",
      "1 1\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction, label\")\n",
    "for i in range(10):\n",
    "    print(y_test[i], predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9645\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       966\n",
      "           1       0.98      0.95      0.97      1034\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.97      0.96      2000\n",
      "weighted avg       0.97      0.96      0.96      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"Accuracy: {}\\n\".format(accuracy_score(y_test, predictions)))\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
